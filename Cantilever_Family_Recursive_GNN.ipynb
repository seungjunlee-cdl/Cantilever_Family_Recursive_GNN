{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421cfdf-fcce-4b34-8e7c-81554e54f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.tri import Triangulation\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import wandb\n",
    "import copy\n",
    "\n",
    "savelen_global = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f99076-8fdc-4d13-8fa2-3ce992583ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 19960926\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "dgl.seed(random_seed)\n",
    "dgl.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11572106-b5a2-46d6-87fe-f9750c03938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    num_nodes = batched_graph.batch_num_nodes()\n",
    "    return batched_graph, torch.tensor(np.vstack(labels))\n",
    "\n",
    "def count_param(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for disjoint_graphs_test, output_features_test in loader:\n",
    "            test_features_unchange = disjoint_graphs_test.ndata['Features'][:,0:5]\n",
    "            test_features_input = disjoint_graphs_test.ndata['Features'][:,5].reshape(disjoint_graphs_test.ndata['Features'].shape[0],1)\n",
    "            graphs4test = copy.copy(disjoint_graphs_test)\n",
    "            test_label = copy.deepcopy(output_features_test[:,savelen_global-2]).reshape(disjoint_graphs_test.ndata['Features'].shape[0],1)\n",
    "            for seq_batch in range(savelen_global-1):\n",
    "                if seq_batch==0:\n",
    "                    test_features = copy.deepcopy(test_features_input)\n",
    "                else:\n",
    "                    test_features = copy.deepcopy(pred_features.to('cpu').detach().numpy())\n",
    "                graphs4test.ndata['Features'] = torch.tensor(np.concatenate((test_features_unchange,test_features),axis=1))\n",
    "                pred_features = model(graphs4test.to('cuda'), graphs4test.ndata['Features'].to('cuda'))\n",
    "                \n",
    "                if seq_batch==savelen_global-2:\n",
    "                    loss_test = MAE_loss(pred_features, test_label.to('cuda'))\n",
    "            break\n",
    "    return loss_test.to('cpu').detach().numpy()\n",
    "\n",
    "def showMeshPlot_seq(nodes,elements,inputs,truth,pred):\n",
    "    x = nodes[:,0]\n",
    "    y = nodes[:,1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.set_aspect('equal')\n",
    "    xy = np.c_[x,y]\n",
    "    verts= xy[elements]\n",
    "    pc = matplotlib.collections.PolyCollection(verts,edgecolor='black',cmap='Greys')\n",
    "    pc.set_array(inputs)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.set_aspect('equal')\n",
    "    xy = np.c_[x,y]\n",
    "    verts= xy[elements]\n",
    "    pc = matplotlib.collections.PolyCollection(verts,edgecolor='black',cmap='Greys')\n",
    "    pc.set_array(truth)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.set_aspect('equal')\n",
    "    xy = np.c_[x,y]\n",
    "    verts= xy[elements]\n",
    "    pc = matplotlib.collections.PolyCollection(verts,edgecolor='black',cmap='Greys')\n",
    "    pc.set_array(pred)\n",
    "    ax.add_collection(pc)\n",
    "    ax.autoscale()\n",
    "\n",
    "def plot_save(model,epoch,savefoldername):\n",
    "    path = '/root/GNN/0_Own/data'\n",
    "    foldermat = ['cantilever','curved','hook_mod','prlgram','winding','bending','trapezoid']\n",
    "    os.makedirs('/root/GNN/0_Own/results' + '/' + savefoldername + '/' + '%d_epoch'%(epoch), exist_ok=True)\n",
    "    \n",
    "    for folder_name in foldermat:\n",
    "        num_data = 500\n",
    "        with open(path  + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'test_index.bin','rb') as test_ind:\n",
    "            plot_test_ind = np.fromfile(test_ind,dtype = 'float32',count=-1).astype(int)\n",
    "        \n",
    "        with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'ptadj.bin','rb') as infomat:\n",
    "            length_p_t_adj = np.fromfile(infomat,dtype = 'float32',count=-1).reshape(3,num_data).transpose([1,0]).astype(int)\n",
    "\n",
    "        randind = np.random.choice(plot_test_ind, replace=False)\n",
    "        coor_num = length_p_t_adj[randind-1,0]\n",
    "        node_num = length_p_t_adj[randind-1,1]\n",
    "        adj_num = length_p_t_adj[randind-1,2]\n",
    "        save_rho_length = savelen_global\n",
    "\n",
    "        with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'p_%d.bin'%(randind),'rb') as ptest:\n",
    "            p = np.fromfile(ptest,dtype='float32',count=-1).reshape(2,coor_num).transpose([1,0])\n",
    "       \n",
    "        with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 't_%d.bin'%(randind),'rb') as ttest:\n",
    "            t = np.fromfile(ttest,dtype='float32',count=-1).reshape(3,node_num).transpose([1,0]).astype(int)\n",
    "\n",
    "        with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'adj_%d.bin'%(randind),'rb') as adj:\n",
    "            adj_list = np.fromfile(adj,dtype='float32',count=-1).reshape(2,adj_num).transpose([1,0])\n",
    "            adj_list = adj_list.astype(int)\n",
    "            adj_list += -1\n",
    "            \n",
    "        graph_plot = dgl.graph((adj_list[:,0],adj_list[:,1]))\n",
    "        graph_plot = dgl.add_self_loop(graph_plot)\n",
    "        graph_plot = dgl.to_bidirected(graph_plot,copy_ndata = True)\n",
    "        \n",
    "        if folder_name in ['cantilever','curved','hook','prlgram','winding']:\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_seq' + '/' + folder_name + '_u_%d.bin'%(randind),'rb') as feat:\n",
    "                features = np.fromfile(feat,dtype='float32',count=-1).reshape(2,node_num).transpose([1,0])\n",
    "\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_stress' + '/' + 'stress_%d.bin'%(randind),'rb') as sig:\n",
    "                stress = np.fromfile(sig,dtype='float32',count=-1).reshape(3,node_num).transpose([1,0])\n",
    "\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(randind)) as rhos:\n",
    "                rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "                rho_mat[:,0] = np.mean(rho_mat[:,1])\n",
    "                \n",
    "            features = np.concatenate((features,stress),axis=1)\n",
    "\n",
    "        elif folder_name in ['bending','trapezoid','hook_mod']:\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_seq' + '/' + folder_name + '_features_%d.bin'%(randind),'rb') as feat:\n",
    "                features = np.fromfile(feat,dtype='float32',count=-1).reshape(5,node_num).transpose([1,0])\n",
    "\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(randind)) as rhos:\n",
    "                rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "\n",
    "\n",
    "        for rho_iter in range(savelen_global-1):\n",
    "            if rho_iter==0:\n",
    "                rho_inputs = rho_mat[:,0].reshape(node_num,1)\n",
    "                node_label = rho_mat[:,1].reshape(node_num,1)\n",
    "            else:\n",
    "                rho_inputs = copy.deepcopy(predictions_plot.detach().numpy())\n",
    "                node_label = rho_mat[:,rho_iter+1].reshape(node_num,1)\n",
    "\n",
    "            node_features = np.concatenate((features,rho_inputs),axis=1)\n",
    "            graph_plot.ndata['Features'] = torch.tensor(node_features)\n",
    "\n",
    "            model = model.to('cpu')\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions_plot = model(graph_plot,graph_plot.ndata['Features'])\n",
    "\n",
    "            showMeshPlot_seq(p,t-1,node_features[:,5].reshape(-1),node_label.reshape(-1),predictions_plot.reshape(-1))\n",
    "            plt.savefig('/root/GNN/0_Own/results/' + savefoldername + '/' + '%d_epoch'%(epoch) + '/' + folder_name+'_seq_%d.jpg'%(rho_iter+1))\n",
    "            plt.close()\n",
    "\n",
    "    model = model.to('cuda')\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def reg_layer(layer_num):\n",
    "    assert len(np.array(layer_num).shape) == 1\n",
    "    num_reg_layer = len(layer_num)\n",
    "    namespace = []\n",
    "    for ln in range(len(layer_num)):\n",
    "        namespace.append('gat%d.fc'%(layer_num[ln])+'.weight')\n",
    "    return namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fce7c99-f1ee-4c8d-ba87-9766bfbef41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2 \n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c7d5e6-6f99-41ef-a9c8-72789f492222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Graph_train(dgl.data.DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='MESH2GRAPH'+ '__' + 'train')\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        path = '/root/GNN/0_Own/data'\n",
    "        folder_list = ['cantilever','curved','hook_mod','prlgram','winding','bending','trapezoid']\n",
    "        num_data = 500\n",
    "\n",
    "        for folder_name in folder_list:\n",
    "            indexmat = np.linspace(1,num_data,num_data).astype(int)\n",
    "            \n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'ptadj.bin','rb') as infomat:\n",
    "                length_p_t_adj = np.fromfile(infomat,dtype = 'float32',count=-1).reshape(3,num_data).transpose([1,0]).astype(int)\n",
    "\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'test_index.bin','rb') as test_ind:\n",
    "                part_test_ind = np.fromfile(test_ind,dtype = 'float32',count=-1).astype(int)\n",
    "            \n",
    "            part_train_ind = np.setdiff1d(indexmat, part_test_ind)\n",
    "            numtrain = 0\n",
    "            \n",
    "            for data_iter in part_train_ind:\n",
    "                numtrain = numtrain+1\n",
    "                node_num = int(length_p_t_adj[data_iter-1,1])\n",
    "                adj_num = int(length_p_t_adj[data_iter-1,2])\n",
    "                save_rho_length = savelen_global\n",
    "                \n",
    "                with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'adj_%d.bin'%(data_iter),'rb') as adj:\n",
    "                    adj_list = np.fromfile(adj,dtype='float32',count=-1).reshape(2,adj_num).transpose([1,0])\n",
    "                    adj_list = adj_list.astype(int)\n",
    "                    adj_list += -1\n",
    "                    \n",
    "                if folder_name in ['cantilever','curved','hook','prlgram','winding']:\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_seq' + '/' + folder_name + '_u_%d.bin'%(data_iter),'rb') as feat:\n",
    "                        features = np.fromfile(feat,dtype='float32',count=-1).reshape(2,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_stress' + '/' + 'stress_%d.bin'%(data_iter),'rb') as sig:\n",
    "                        stress = np.fromfile(sig,dtype='float32',count=-1).reshape(3,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(data_iter)) as rhos:\n",
    "                        rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "                        rho_mat[:,0] = np.mean(rho_mat[:,1])\n",
    "                        \n",
    "                    node_features = np.concatenate((features,stress,rho_mat[:,0:savelen_global-1]),axis=1)\n",
    "                    node_label = rho_mat[:,1:savelen_global]\n",
    "\n",
    "                elif folder_name in ['bending','trapezoid','hook_mod']:\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_seq' + '/' + folder_name + '_features_%d.bin'%(data_iter),'rb') as feat:\n",
    "                        features = np.fromfile(feat,dtype='float32',count=-1).reshape(5,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(data_iter)) as rhos:\n",
    "                        rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "                        \n",
    "                    node_features = np.concatenate((features,rho_mat[:,0:savelen_global-1]),axis=1)\n",
    "                    node_label = rho_mat[:,1:savelen_global]\n",
    "\n",
    "                assert rho_mat.shape[1]==savelen_global\n",
    "                assert node_features.shape[1]==node_label.shape[1]+5\n",
    "\n",
    "                g = dgl.graph((adj_list[:,0],adj_list[:,1]))\n",
    "                g.ndata['Features'] = torch.tensor(node_features)\n",
    "                g = dgl.add_self_loop(g)\n",
    "                g = dgl.to_bidirected(g,copy_ndata = True)\n",
    "\n",
    "                self.graphs.append(g)\n",
    "                self.labels.append(node_label)\n",
    "                                        \n",
    "                print('Category Name : %s   Data Num : %d   Feature shape : (%d , %d)   Label shape : (%d , %d)'\\\n",
    "                      %(folder_name,numtrain,node_features.shape[0],node_features.shape[1],node_label.shape[0],node_label.shape[1]))\n",
    "                clear_output(wait=True)\n",
    "                    \n",
    "        print('Graph Representation Done')\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad881908-1552-4e72-a165-468db9e10582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Graph_test(dgl.data.DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='MESH2GRAPH'+ '__' + 'test')\n",
    "\n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "\n",
    "        path = '/root/GNN/0_Own/data'\n",
    "        folder_list = ['cantilever','curved','hook_mod','prlgram','winding','bending','trapezoid']\n",
    "        num_data = 500\n",
    "\n",
    "        for folder_name in folder_list:\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'ptadj.bin','rb') as infomat:\n",
    "                length_p_t_adj = np.fromfile(infomat,dtype = 'float32',count=-1).reshape(3,num_data).transpose([1,0]).astype(int)\n",
    "\n",
    "            with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'test_index.bin','rb') as test_ind:\n",
    "                part_test_ind = np.fromfile(test_ind,dtype = 'float32',count=-1).astype(int)\n",
    "            \n",
    "            numtest = 0\n",
    "            for data_iter in part_test_ind:\n",
    "                numtest = numtest+1\n",
    "                node_num = int(length_p_t_adj[data_iter-1,1])\n",
    "                adj_num = int(length_p_t_adj[data_iter-1,2])\n",
    "                save_rho_length = savelen_global\n",
    "                \n",
    "                with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '/' + 'adj_%d.bin'%(data_iter),'rb') as adj:\n",
    "                    adj_list = np.fromfile(adj,dtype='float32',count=-1).reshape(2,adj_num).transpose([1,0])\n",
    "                    adj_list = adj_list.astype(int)\n",
    "                    adj_list += -1\n",
    "                    \n",
    "                if folder_name in ['cantilever','curved','hook','prlgram','winding']:\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_seq' + '/' + folder_name + '_u_%d.bin'%(data_iter),'rb') as feat:\n",
    "                        features = np.fromfile(feat,dtype='float32',count=-1).reshape(2,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_stress' + '/' + 'stress_%d.bin'%(data_iter),'rb') as sig:\n",
    "                        stress = np.fromfile(sig,dtype='float32',count=-1).reshape(3,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/' + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(data_iter)) as rhos:\n",
    "                        rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "                        rho_mat[:,0] = np.mean(rho_mat[:,1])\n",
    "\n",
    "                    node_features = np.concatenate((features,stress,rho_mat[:,0:savelen_global-1]),axis=1)\n",
    "                    node_label = rho_mat[:,1:savelen_global]\n",
    "                    \n",
    "                \n",
    "                elif folder_name in ['bending','trapezoid','hook_mod']:\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/'  + folder_name + '_seq' + '/' + folder_name + '_features_%d.bin'%(data_iter),'rb') as feat:\n",
    "                        features = np.fromfile(feat,dtype='float32',count=-1).reshape(5,node_num).transpose([1,0])\n",
    "\n",
    "                    with open(path + '/' + folder_name + '_folders' + '/'  + folder_name + '_%dseq'%(savelen_global) + '/' + folder_name + '_%d.bin'%(data_iter)) as rhos:\n",
    "                        rho_mat = np.fromfile(rhos,dtype='float32',count=-1).reshape(save_rho_length,node_num).transpose([1,0])\n",
    "                    \n",
    "                    node_features = np.concatenate((features,rho_mat[:,0:savelen_global-1]),axis=1)\n",
    "                    node_label = rho_mat[:,1:savelen_global]\n",
    "\n",
    "                assert rho_mat.shape[1]==savelen_global\n",
    "                assert node_features.shape[1]==node_label.shape[1]+5\n",
    "\n",
    "                g = dgl.graph((adj_list[:,0],adj_list[:,1]))\n",
    "                g.ndata['Features'] = torch.tensor(node_features)\n",
    "                g = dgl.add_self_loop(g)\n",
    "                g = dgl.to_bidirected(g,copy_ndata = True)\n",
    "\n",
    "                self.graphs.append(g)\n",
    "                self.labels.append(node_label)\n",
    "                \n",
    "                print('Category Name : %s   Data Num : %d   Feature shape : (%d , %d)   Label shape : (%d , %d)'\\\n",
    "                      %(folder_name,numtest,node_features.shape[0],node_features.shape[1],node_label.shape[0],node_label.shape[1]))\n",
    "                clear_output(wait=True)\n",
    "                    \n",
    "        print('Graph Representation Done')\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f123c119-97c4-4a01-b375-acb1b0c41767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOP_MODEL(torch.nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden_features):\n",
    "        super().__init__()\n",
    "        assert num_layers%2 ==0, 'Number of Layers is not Even : Skip connection operation is obscure'\n",
    "        assert num_hidden_features < 512, 'Number of Hidden Features is too Large'\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden_features = num_hidden_features\n",
    "        self.att_head = 2\n",
    "\n",
    "        for nl in range(1,self.num_layers+1):\n",
    "            if nl==1:\n",
    "                self.gat1 = dgl.nn.pytorch.conv.GATConv(in_feats=6,out_feats=self.num_hidden_features,num_heads=self.att_head,bias=False)\n",
    "                self.bn1 = torch.nn.BatchNorm1d(num_features = self.num_hidden_features)\n",
    "                self.act1 = torch.nn.ReLU()\n",
    "            \n",
    "            elif ((nl<=self.num_layers/2) and (nl%3==1)) or ((nl>self.num_layers/2) and (nl%3==0)):\n",
    "                in_GCN_tmp = \"self.gat%d\"%(nl)\n",
    "                in_BN_tmp = \"self.bn%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "                \n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GATConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,num_heads=self.att_head,bias=False)\"\n",
    "                BN_tmp = \"torch.nn.BatchNorm1d(num_features = self.num_hidden_features)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "                \n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_BN_tmp,BN_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "            \n",
    "            elif ((nl<=self.num_layers/2) and (nl%3==2)) or ((nl>self.num_layers/2) and (nl%3==2)):\n",
    "                in_GCN_tmp = \"self.gat%d\"%(nl)\n",
    "                in_DO_tmp = \"self.do%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "\n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GATConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,num_heads=self.att_head,bias=True)\"\n",
    "                DO_tmp = \"torch.nn.Dropout(p=0.2)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "\n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_DO_tmp,DO_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "\n",
    "            elif ((nl<=self.num_layers/2) and (nl%3==0)) or ((nl>self.num_layers/2) and (nl%3==1)):\n",
    "                in_GCN_tmp = \"self.gat%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "\n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GATConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,num_heads=self.att_head,bias=True)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "\n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "\n",
    "        self.gat_last = dgl.nn.pytorch.conv.GATConv(in_feats=self.num_hidden_features,out_feats=1,num_heads=self.att_head,bias=True)\n",
    "        self.act_last = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, graphs, features):\n",
    "        for i in range(1,self.num_layers+1):\n",
    "            if i==1:\n",
    "                self.c1 = self.gat1(graphs, features).mean(dim=1)\n",
    "                self.b1 = self.bn1(self.c1)\n",
    "                self.a1 = self.act1(self.b1)\n",
    "            elif (i<=self.num_layers/2) and (i%3==1):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.b%d = self.bn%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.a%d = self.act%d(self.b%d)'%(i,i,i))\n",
    "            elif (i<=self.num_layers/2) and (i%3==2):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.d%d = self.do%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.a%d = self.act%d(self.d%d)'%(i,i,i))\n",
    "            elif (i<=self.num_layers/2) and (i%3==0):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.a%d = self.act%d(self.c%d)'%(i,i,i))\n",
    "\n",
    "            elif (i>self.num_layers/2) and (i%3==1):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.skip%d = self.a%d + self.c%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            elif (i>self.num_layers/2) and (i%3==2):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.d%d = self.do%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.skip%d = self.a%d + self.d%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            elif (i>self.num_layers/2) and (i%3==0):\n",
    "                exec('self.c%d = self.gat%d(graphs, self.a%d).mean(dim=1)'%(i,i,i-1))\n",
    "                exec('self.b%d = self.bn%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.skip%d = self.a%d + self.b%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            \n",
    "        exec('self.c_last = self.gat_last(graphs, self.a%d).mean(dim=1)'%(self.num_layers))\n",
    "        out = self.act_last(self.c_last)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8838f82f-aa36-4e85-85c2-3583bd7daa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation Done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Seq2Graph_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e93afc3-9d17-4741-a32d-309fc0d89cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation Done\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Seq2Graph_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92bfcca2-9635-4ecf-8f04-589a2599a032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__len__())\n",
    "print(test_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "171a0be1-ef8b-4021-827a-fb676348397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 18\n",
    "num_hidden_features = 128\n",
    "model = TOP_MODEL(num_layers,num_hidden_features)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855744a6-8254-467d-b177-265dc5a8b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dgl.dataloading.pytorch.GraphDataLoader(train_dataset, collate_fn=collate, batch_size=128, shuffle=True)\n",
    "test_loader = dgl.dataloading.pytorch.GraphDataLoader(test_dataset, collate_fn=collate, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9fa32d-8d52-4c1c-98a0-c649a97dedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=200, T_mult=1, eta_max=0.005, T_up=40, gamma=0.5)\n",
    "MAE_loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcfaafba-2be5-4af9-8866-1515f1e04712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gat3.fc.weight', 'gat6.fc.weight', 'gat9.fc.weight', 'gat10.fc.weight', 'gat13.fc.weight', 'gat16.fc.weight']\n"
     ]
    }
   ],
   "source": [
    "reg_layer_num = []\n",
    "for ln in range(1,num_layers+1):\n",
    "    if (ln<=num_layers/2) and (ln%3==0):\n",
    "        reg_layer_num.append(ln)\n",
    "    elif (ln>num_layers/2) and (ln%3==1):\n",
    "        reg_layer_num.append(ln)\n",
    "reg_layer_namespace = reg_layer(reg_layer_num)\n",
    "print(reg_layer_namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e701b0ef-2bb1-45b3-8860-7054d58e910e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 500     Batch : 22     Seq : 5     Training loss : 0.099155     reg loss : 0.000087     Learning rate : 0.000875\n"
     ]
    }
   ],
   "source": [
    "emax = 500\n",
    "min_test_err = [1]\n",
    "modelsave_interval = 100\n",
    "plotsave_interval = 100\n",
    "l2reg_factor = 0.005\n",
    "experiment_name = \"V6_RNN_all_%dseq_hook_mod\"%(savelen_global)\n",
    "wandb.init(project=\"GNN_seq_FINAL\",group=experiment_name)\n",
    "config = wandb.config\n",
    "\n",
    "save_fig_foldername = 'V6_RNN_all_%dseq_hook_mod'%(savelen_global)\n",
    "save_interv_model_foldername = experiment_name + '_interv'\n",
    "save_best_model_foldername = experiment_name + '_best'\n",
    "\n",
    "intervmodel_path = '/root/GNN/0_Own/models/' + save_interv_model_foldername\n",
    "bestmodel_path = '/root/GNN/0_Own/models/' + save_best_model_foldername\n",
    "os.makedirs(intervmodel_path, exist_ok=True)\n",
    "os.makedirs(bestmodel_path, exist_ok=True)\n",
    "\n",
    "for e in range(1,emax+1):\n",
    "    for batch_num, (disjoint_graphs, output_features) in enumerate(train_loader):\n",
    "        train_features_unchange = copy.deepcopy(disjoint_graphs.ndata['Features'][:,0:5])\n",
    "        train_features_change = copy.deepcopy(disjoint_graphs.ndata['Features'][:,5:])\n",
    "        graphs4train = copy.deepcopy(disjoint_graphs)\n",
    "        for seq_batch in range(savelen_global-1):\n",
    "            if seq_batch==0:\n",
    "                train_features = copy.deepcopy(train_features_change[:,seq_batch]).reshape(disjoint_graphs.ndata['Features'].shape[0],1)\n",
    "            else:\n",
    "                train_features = next_feat\n",
    "            train_label = copy.deepcopy(output_features[:,seq_batch]).reshape(disjoint_graphs.ndata['Features'].shape[0],1)\n",
    "\n",
    "            graphs4train.ndata['Features'] = torch.tensor(np.concatenate((train_features_unchange,train_features),axis=1))\n",
    "\n",
    "            pred_features = model(graphs4train.to('cuda'), graphs4train.ndata['Features'].to('cuda'))\n",
    "            loss_training = MAE_loss(pred_features, train_label.to('cuda'))\n",
    "            loss_reg = 0\n",
    "            for parameter in model.named_parameters():\n",
    "                for i in range(len(reg_layer_namespace)):\n",
    "                    if reg_layer_namespace[i] in parameter:\n",
    "                        loss_reg += torch.sum(parameter[1]**2)\n",
    "            loss_training = loss_training + l2reg_factor*loss_reg\n",
    "            optimizer.zero_grad()\n",
    "            loss_training.backward()\n",
    "            optimizer.step()\n",
    "            next_feat = copy.copy(pred_features).to('cpu').detach().numpy()\n",
    "        \n",
    "            print('Epoch : %d     Batch : %d     Seq : %d     Training loss : %f     reg loss : %f     Learning rate : %f'% \\\n",
    "                  (e,batch_num+1,seq_batch+1,loss_training,loss_reg,scheduler.get_lr()[0]))\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "    loss_test = evaluate(model,test_loader)\n",
    "    scheduler.step()\n",
    "    wandb.log({\"training_loss\":loss_training, \"test_loss\":loss_test, \"learning_rate\":scheduler.get_lr()[0]})\n",
    "    \n",
    "    if e%plotsave_interval ==0:\n",
    "        plot_save(model,e,save_fig_foldername)\n",
    "    if e%modelsave_interval == 0:\n",
    "        torch.save(model.state_dict(),intervmodel_path + '/' + 'model_%d_epoch'%(e))\n",
    "    if min_test_err > loss_test:\n",
    "        torch.save(model.state_dict(),bestmodel_path + '/' + 'best_model')\n",
    "        min_test_err = copy.copy([loss_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5dc387-0661-4058-9291-2dae76c88f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
